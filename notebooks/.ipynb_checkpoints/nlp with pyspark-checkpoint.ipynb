{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps in NLP\n",
    "\n",
    "1. Reading the corpus\n",
    "2. Tokenization\n",
    "3. Cleaning/Stopward removal\n",
    "4. Stemming\n",
    "5. Converting into numerical form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "sc = SparkContext('local', 'NLP with PySpark')\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axisdata.csv\t\t       Log_Reg_dataset.csv  Movie_reviews.csv\r\n",
      "Linear_regression_dataset.csv  movie_reviews.csv    sample_data.csv\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../datasets/nlp_with_pyspark/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = spark.read.csv('../datasets/nlp_with_pyspark/movie_reviews.csv',\n",
    "                        inferSchema=True, header=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Review: string (nullable = true)\n",
      " |-- Sentiment: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_text.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7087"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some might not be labelled properly hence we will filter out those records<br>\n",
    "we will only keep the ones with 0/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text=df_text.filter((df_text.Sentiment == '1')|(df_text.Sentiment == '0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6990"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|Sentiment|count|\n",
      "+---------+-----+\n",
      "|        0| 3081|\n",
      "|        1| 3909|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_text.groupBy('Sentiment').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------+---------+\n",
      "|Review                                                                  |Sentiment|\n",
      "+------------------------------------------------------------------------+---------+\n",
      "|The Da Vinci Code sucked big time.                                      |0        |\n",
      "|What I'd like to see is some Mission Impossible stuff, maybe throw them |1        |\n",
      "|Harry Potter = Gorgeous!.                                               |1        |\n",
      "|I OFFICIALLY * HATE * BROKEBACK MOUNTAIN!!!!!!!!!!!                     |0        |\n",
      "|i love being a sentry for mission impossible and a station for bonkers. |1        |\n",
      "|The Da Vinci Code sucked big time.                                      |0        |\n",
      "|I love Brokeback Mountain.                                              |1        |\n",
      "|Mission Impossible 3 was excellent.                                     |1        |\n",
      "|I am going to start reading the Harry Potter series again because that i|1        |\n",
      "|I think I hate Harry Potter because it outshines much better reading mat|0        |\n",
      "+------------------------------------------------------------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_text.orderBy(rand()).show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### now we will create an Integer type column for sentiment instead of a string type column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text=df_text.withColumn('Label', df_text.Sentiment.cast('float')).drop('Sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------+-----+\n",
      "|Review                                                                  |Label|\n",
      "+------------------------------------------------------------------------+-----+\n",
      "|I love all the Mission Impossible movies, and this one is no exception. |1.0  |\n",
      "|I hate Harry Potter, that daniel wotshisface needs a fucking slap...    |0.0  |\n",
      "|I wanted desperately to love'The Da Vinci Code as a film.               |1.0  |\n",
      "|\"Anyway, thats why I love \"\" Brokeback Mountain.\"                       |1.0  |\n",
      "|Because I would like to make friends who like the same things I like, an|1.0  |\n",
      "|Harry Potter dragged Draco Malfoy â€™ s trousers down past his hips and   |0.0  |\n",
      "|These Harry Potter movies really suck.                                  |0.0  |\n",
      "|Oh, and Brokeback Mountain is a TERRIBLE movie...                       |0.0  |\n",
      "|dudeee i LOVED brokeback mountain!!!!                                   |1.0  |\n",
      "|I wanted desperately to love'The Da Vinci Code as a film.               |1.0  |\n",
      "+------------------------------------------------------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_text.orderBy(rand()).show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### adding another column indicating length of the review column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text=df_text.withColumn('length', length(df_text['Review']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------+-----+------+\n",
      "|Review                                                                  |Label|length|\n",
      "+------------------------------------------------------------------------+-----+------+\n",
      "|brokeback mountain is such a beautiful movie.                           |1.0  |45    |\n",
      "|This quiz sucks and Harry Potter sucks ok bye..                         |0.0  |47    |\n",
      "|Is it just me, or does Harry Potter suck?...                            |0.0  |44    |\n",
      "|And Da Vinci Code is awesome.                                           |1.0  |29    |\n",
      "|I am going to start reading the Harry Potter series again because that i|1.0  |72    |\n",
      "|The Da Vinci Code is awesome!!                                          |1.0  |30    |\n",
      "|\"I liked the first \"\" Mission Impossible.\"                              |1.0  |42    |\n",
      "|I hate Harry Potter, it's retarted, gay and stupid and there's only one |0.0  |71    |\n",
      "|I love Brokeback Mountain....                                           |1.0  |29    |\n",
      "|So Brokeback Mountain was really depressing.                            |0.0  |44    |\n",
      "+------------------------------------------------------------------------+-----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_text.orderBy(rand()).show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|Label|      avg(Length)|\n",
      "+-----+-----------------+\n",
      "|  1.0|47.61882834484523|\n",
      "|  0.0|50.95845504706264|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_text.groupBy('Label').agg({'Length': 'mean'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we don't see any major difference between the average length of the positive and negative reviews. Now we will tokenize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenization = Tokenizer(inputCol='Review', outputCol='tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokenized = tokenization.transform(df_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_removal = StopWordsRemover(inputCol='tokens',\n",
    "                                  outputCol='refined_tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_refined_text = stopword_removal.transform(df_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we will calculate number of tokens of each column since we are dealing with tokens now instead of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_udf = udf(lambda s: len(s), IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_refined_text=df_refined_text.withColumn(\"token_count\",\n",
    "                                          len_udf(col('refined_tokens')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------+--------------------+--------------------+-----------+\n",
      "|              Review|Label|length|              tokens|      refined_tokens|token_count|\n",
      "+--------------------+-----+------+--------------------+--------------------+-----------+\n",
      "|I hated Brokeback...|  0.0|    27|[i, hated, brokeb...|[hated, brokeback...|          3|\n",
      "|I either LOVE Bro...|  1.0|    71|[i, either, love,...|[either, love, br...|          7|\n",
      "|friday hung out w...|  0.0|    72|[friday, hung, ou...|[friday, hung, ke...|          9|\n",
      "|dudeee i LOVED br...|  1.0|    37|[dudeee, i, loved...|[dudeee, loved, b...|          4|\n",
      "|I hate Harry Potter.|  0.0|    20|[i, hate, harry, ...|[hate, harry, pot...|          3|\n",
      "|I love Brokeback ...|  1.0|    29|[i, love, brokeba...|[love, brokeback,...|          3|\n",
      "|Da Vinci code is ...|  1.0|    25|[da, vinci, code,...|[da, vinci, code,...|          4|\n",
      "|Harry Potter drag...|  0.0|    69|[harry, potter, d...|[harry, potter, d...|          9|\n",
      "|the last stand an...|  1.0|    65|[the, last, stand...|[last, stand, mis...|          7|\n",
      "|we're gonna like ...|  1.0|    51|[we're, gonna, li...|[gonna, like, wat...|          6|\n",
      "+--------------------+-----+------+--------------------+--------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_refined_text.orderBy(rand()).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we have refined tokens after stopword removal, we can use any of the above approaches to convert text into numerical features.  In this case, we use a countvectorizer for feature vectorization for the machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(inputCol='refined_tokens',\n",
    "                            outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv_text=count_vec.fit(df_refined_text).transform(df_refined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+--------------------+-----+\n",
      "|      refined_tokens|token_count|            features|Label|\n",
      "+--------------------+-----------+--------------------+-----+\n",
      "|[da, vinci, code,...|          5|(2302,[0,1,4,43,2...|  1.0|\n",
      "|[first, clive, cu...|          9|(2302,[11,51,229,...|  1.0|\n",
      "|[liked, da, vinci...|          5|(2302,[0,1,4,53,3...|  1.0|\n",
      "|[liked, da, vinci...|          5|(2302,[0,1,4,53,3...|  1.0|\n",
      "|[liked, da, vinci...|          8|(2302,[0,1,4,53,6...|  1.0|\n",
      "|[even, exaggerati...|          6|(2302,[46,229,271...|  1.0|\n",
      "|[loved, da, vinci...|          8|(2302,[0,1,22,30,...|  1.0|\n",
      "|[thought, da, vin...|          7|(2302,[0,1,4,228,...|  1.0|\n",
      "|[da, vinci, code,...|          6|(2302,[0,1,4,33,2...|  1.0|\n",
      "|[thought, da, vin...|          7|(2302,[0,1,4,223,...|  1.0|\n",
      "+--------------------+-----------+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cv_text.select(['refined_tokens', 'token_count', 'features', 'Label']).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_text=df_cv_text.select(['features', 'token_count', 'Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we have feature vector for each row, we can make use of VectorAssembler to create input features for machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assembler = VectorAssembler(inputCols=['features', 'token_count'],\n",
    "                              outputCol='features_vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_text = df_assembler.transform(df_model_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- token_count: integer (nullable = true)\n",
      " |-- Label: float (nullable = true)\n",
      " |-- features_vec: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_model_text.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### we can use any of the classification model, but we generally try linear regression first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training, df_test = df_model_text.randomSplit([0.75,0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|Label|count|\n",
      "+-----+-----+\n",
      "|  1.0| 2964|\n",
      "|  0.0| 2280|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_training.groupBy('Label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|Label|count|\n",
      "+-----+-----+\n",
      "|  1.0|  945|\n",
      "|  0.0|  801|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test.groupBy('Label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(featuresCol='features_vec', labelCol='Label').fit(df_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### now we evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = log_reg.evaluate(df_test).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-----+--------------------+--------------------+--------------------+----------+\n",
      "|            features|token_count|Label|        features_vec|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----------+-----+--------------------+--------------------+--------------------+----------+\n",
      "|(2302,[0,1,4,5,30...|          5|  1.0|(2303,[0,1,4,5,30...|[-22.123993180017...|[2.46417668500255...|       1.0|\n",
      "|(2302,[0,1,4,10,2...|         11|  0.0|(2303,[0,1,4,10,2...|[17.1895591385806...|[0.99999996574931...|       0.0|\n",
      "|(2302,[0,1,4,11,2...|         10|  0.0|(2303,[0,1,4,11,2...|[45.3133904036052...|[1.0,2.0923994219...|       0.0|\n",
      "|(2302,[0,1,4,12,1...|          5|  1.0|(2303,[0,1,4,12,1...|[-28.892175567477...|[2.83326750617783...|       1.0|\n",
      "|(2302,[0,1,4,12,3...|          5|  1.0|(2303,[0,1,4,12,3...|[-24.555254355521...|[2.16664885491525...|       1.0|\n",
      "|(2302,[0,1,4,12,3...|          5|  1.0|(2303,[0,1,4,12,3...|[-24.555254355521...|[2.16664885491525...|       1.0|\n",
      "|(2302,[0,1,4,12,3...|          5|  1.0|(2303,[0,1,4,12,3...|[-24.555254355521...|[2.16664885491525...|       1.0|\n",
      "|(2302,[0,1,4,12,3...|          5|  1.0|(2303,[0,1,4,12,3...|[-24.555254355521...|[2.16664885491525...|       1.0|\n",
      "|(2302,[0,1,4,12,3...|          5|  1.0|(2303,[0,1,4,12,3...|[-24.555254355521...|[2.16664885491525...|       1.0|\n",
      "|(2302,[0,1,4,12,3...|          5|  1.0|(2303,[0,1,4,12,3...|[-24.555254355521...|[2.16664885491525...|       1.0|\n",
      "|(2302,[0,1,4,12,3...|          5|  1.0|(2303,[0,1,4,12,3...|[-24.555254355521...|[2.16664885491525...|       1.0|\n",
      "|(2302,[0,1,4,12,3...|          5|  1.0|(2303,[0,1,4,12,3...|[-24.555254355521...|[2.16664885491525...|       1.0|\n",
      "|(2302,[0,1,4,12,3...|          5|  1.0|(2303,[0,1,4,12,3...|[-24.555254355521...|[2.16664885491525...|       1.0|\n",
      "|(2302,[0,1,4,12,3...|          5|  1.0|(2303,[0,1,4,12,3...|[-24.555254355521...|[2.16664885491525...|       1.0|\n",
      "|(2302,[0,1,4,12,3...|          5|  1.0|(2303,[0,1,4,12,3...|[-24.555254355521...|[2.16664885491525...|       1.0|\n",
      "|(2302,[0,1,4,12,3...|          5|  1.0|(2303,[0,1,4,12,3...|[-24.555254355521...|[2.16664885491525...|       1.0|\n",
      "|(2302,[0,1,4,12,3...|          5|  1.0|(2303,[0,1,4,12,3...|[-24.555254355521...|[2.16664885491525...|       1.0|\n",
      "|(2302,[0,1,4,12,3...|          5|  1.0|(2303,[0,1,4,12,3...|[-24.555254355521...|[2.16664885491525...|       1.0|\n",
      "|(2302,[0,1,4,12,3...|          5|  1.0|(2303,[0,1,4,12,3...|[-24.555254355521...|[2.16664885491525...|       1.0|\n",
      "|(2302,[0,1,4,12,3...|          5|  1.0|(2303,[0,1,4,12,3...|[-24.555254355521...|[2.16664885491525...|       1.0|\n",
      "+--------------------+-----------+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positives = results[(results.Label == 1) & (results.prediction == 1)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_negatives = results[(results.Label == 0) & (results.prediction == 0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives = results[(results.Label == 0) & (results.prediction == 1)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives = results[(results.Label == 1) & (results.prediction == 0)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PERFORMANCE OF THE MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9873015873015873\n"
     ]
    }
   ],
   "source": [
    "recall = float(true_positives)/(true_positives + false_negatives)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97288842544317\n"
     ]
    }
   ],
   "source": [
    "precision = float(true_positives)/(true_positives+false_positives)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=float((true_positives + true_negatives) /(results.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9782359679266895\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
