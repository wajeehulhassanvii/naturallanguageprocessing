{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neo4j in /opt/conda/lib/python3.7/site-packages (4.0.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from neo4j) (2020.1)\n",
      "Requirement already satisfied: spark-nlp in /opt/conda/lib/python3.7/site-packages (2.5.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install neo4j\n",
    "! pip install spark-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import sparknlp\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import lit, col\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp import DocumentAssembler, Finisher\n",
    "from sparknlp.annotator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = [\n",
    "    'JohnSnowLabs:spark-nlp:2.5.0',\n",
    "    'com.databricks:spark-xml_2.11:0.6.0'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "packages = [\n",
    "    'JohnSnowLabs:spark-nlp:2.2.2',\n",
    "    'com.databricks:spark-xml_2.11:0.6.0'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "    .master('local[*]')\\\n",
    "    .appName('Knowledge Graph')\\\n",
    "    .config('spark.driver.memory', '10g')\\\n",
    "    .config('spark.jars.packages', ','.join(packages))\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simplewiki-20200601-pages-articles-multistream-index.txt.bz2\r\n",
      "simplewiki-20200601-pages-articles-multistream.xml.bz2\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../datasets/wiki_data_for_knowledge_base/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read\\\n",
    "    .format('xml')\\\n",
    "    .option('rootTag', 'mediawiki')\\\n",
    "    .option('rowTag', 'page')\\\n",
    "    .load('../datasets/wiki_data_for_knowledge_base/simplewiki-20200601-pages-articles-multistream.xml.bz2')\\\n",
    "    .persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- ns: long (nullable = true)\n",
      " |-- redirect: struct (nullable = true)\n",
      " |    |-- _VALUE: string (nullable = true)\n",
      " |    |-- _title: string (nullable = true)\n",
      " |-- restrictions: string (nullable = true)\n",
      " |-- revision: struct (nullable = true)\n",
      " |    |-- comment: struct (nullable = true)\n",
      " |    |    |-- _VALUE: string (nullable = true)\n",
      " |    |    |-- _deleted: string (nullable = true)\n",
      " |    |-- contributor: struct (nullable = true)\n",
      " |    |    |-- _VALUE: string (nullable = true)\n",
      " |    |    |-- _deleted: string (nullable = true)\n",
      " |    |    |-- id: long (nullable = true)\n",
      " |    |    |-- ip: string (nullable = true)\n",
      " |    |    |-- username: string (nullable = true)\n",
      " |    |-- format: string (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- minor: string (nullable = true)\n",
      " |    |-- model: string (nullable = true)\n",
      " |    |-- parentid: long (nullable = true)\n",
      " |    |-- sha1: string (nullable = true)\n",
      " |    |-- text: struct (nullable = true)\n",
      " |    |    |-- _VALUE: string (nullable = true)\n",
      " |    |    |-- _bytes: long (nullable = true)\n",
      " |    |    |-- _space: string (nullable = true)\n",
      " |    |-- timestamp: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306635"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looking at page for \"Paper\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df.filter('title = \"Paper\"').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID 3319\n",
      "Title Paper\n",
      "\n",
      "redirect None\n",
      "\n",
      "text\n",
      "[[File:Cranes made by Origami paper.jpg|thumb|132x132px|Paper creations]]\n",
      "[[File:InternationalPaper6413.jpg|right|frame|[[International Paper]] is the world’s largest pulp and paper maker]]\n",
      "[[File:Gutenberg bible Old Testament Epistle of St Jerome.jpg|thumb|right|250px|Before about 1820, most printed books used [[wikt:rag|rag]] paper, usually made from waste cotton rags]]\n",
      "[[File:Manuscripts in the Yunnan Nationalities Museum - DSC03947.JPG|thumb|right|250px|Dai scripture on [[mulberry]]-bark paper, Yunnan, China]]\n",
      "[[File:Papyrus.jpg|thumb|right|250px|Writing on [[papyrus]]]]\n",
      "[[File:Ruins of the guard tower.jpg|thumb|right|220px|Ruins of a watchtower on the [[Great Wall of China]]: see \"first paper\"]]\n",
      "\n",
      "Modern '''paper''' is a thin [[material]] of (mostly) [[wood fibre]]s pressed together. People write on paper with a [[pencil]] or [[pen]], and [[book]]s are made of paper. Paper can absorb [[liquid]]s such as [[water]], so people can clean things with paper.\n",
      "\n",
      "The '''pulp and paper industry''' comprises companies that use wood as raw material and produce [[Pulp (paper)|pulp]], paper, board and other cellulose-based products.\n",
      "\n",
      "== Paper making ==\n",
      "Modern paper is normally made from [[wood]] [[wikt:pulp|pulp]].<ref>{{cite book|page=3|title=The Quantum Universe: everything that can happen does happen|publisher=Allen Lane|date=2011|first1=Brian|first2=Jeff|last1=Cox|last2=Forshaw|isbn=978-1-846-14432-5}}</ref> Wood is ground up and mixed with [[water]] and other [[chemical]]s to make a thin liquid called \"paper pulp\". Paper pulp can be [[Sodium hypochlorite|bleached]] to make paper more white, and [[dye]]s can be added to make colored paper. This pulp is pressed into [[wikt:sheet|sheets]] of paper. Printing is often done on paper before the paper is cut into sheets. Newsprint paper (newspaper) comes in a huge roll, and goes through the printing process as one continuous sheet. It is cut by a machine-driven [[guillotine]] blade later. Folding comes last, then packing for distribution. \n",
      "\n",
      "Sometimes paper is made heavier and more glossy (shiny) by adding [[clay]], and by 'milling' it. Milling is done by [[wikt:squeeze|squeezing]] the paper through a series of rollers. Sometimes paper is made from used or waste paper: this is [[recycling]].\n",
      "\n",
      "Not all paper is made from wood. Other kinds of fiber can be used. People still make paper from [[cotton]], [[linen]] and [[hemp]] for special purposes.\n",
      "\n",
      "== History of paper ==\n",
      "[[Writing]] started long before the invention of paper. People wrote on many kinds of material. They wrote on cloth, on the stone walls and on wood. In [[Mesopotamia]] the [[Sumer]]ians wrote on [[clay]] tablets, many of which have survived today. In Europe, people wrote on [[vellum]].\n",
      "\n",
      "=== First paper ===\n",
      "Many [[century|centuries]] ago&nbsp;–&nbsp;as early as the [[3rd millennium BC]] (that's over 2000 BC)&nbsp;–&nbsp;people in [[Egypt]] made a kind of paper from the [[papyrus]] plant.<ref name = Skeat>[http://www-user.uni-bremen.de/~wie/Egerton/BellSkeat2.html H. Idris Bell and T.C. Skeat, 1935. \"Papyrus and its uses\"] ([[British Museum]] pamphlet).</ref> This is where the word 'paper' comes from. The people of [[Greece]] and [[Rome]] learned to do this too. The Romans wrote on [[parchment]] (made from animal skin), on [[wax]]ed tablets and on wood (see [[Vindolanda]]).\n",
      "\n",
      "In [[China]] 105 AD, the [[eunuch]] [[Cai Lun]] told his Emperor he had made paper. They had previously used [[bamboo]] and [[silk]].<ref>Han dynasty 206BC–220 AD.</ref><ref name=Carter>Carter, Thomas Francis 1925. ''The invention of printing in China and its spread westward''. Columbia N.Y.</ref> The material used in this ancient paper included [[cotton]] [[wikt:rag|rags]], [[hemp]], various plant fibres and old [[Fishing net|fish nets]]. The oldest existing paper with writing on it was found in the ruins of a watchtower in the [[Great Wall of China]]. It dates to about 150 AD.<ref name=Carter/><sup>p5</sup><ref>Stein, M. Aurel 1921. ''Serindia''. London 1921.</ref><ref>Papermaking. 2007. In: ''Encyclopedia Britannica'', from ''Encyclopedia Britannica Online''.</ref> Even earlier paper (but with no writing on it) has been claimed: \"The oldest surviving piece of paper in the world is made of hemp fibers, discovered in 1957 in a tomb near Xian, China, and dates from between the years 140 and 87 BC\".<ref>Temple, Robert 1986. ''The genius of China: 3,000 Years of science, discovery, and invention''. Simon and Schuster, New York.</ref> Paper-making was regarded by the Chinese as so valuable that they kept it secret as long as they could.\n",
      "\n",
      "=== Spread of paper ===\n",
      "People in [[Japan]] learned how to make paper with fibres of the [[mulberry]] tree, around 610 AD. This is called Japanese paper or ''[[Washi]]''. The Chinese invention spread to [[India]], and then to the [[Middle East]], and then to [[Italy]].\n",
      "\n",
      "An opportunity occurred after The Battle of Talas in 751. Then an [[Arab]] army captured soldiers of the Chinese. There were some paper makers among the captured soldiers. From them, paper-making spread throughout the [[Islamic world]].  In 757, a paper mill was built at [[Samarkand]]. People learned to use [[linen]] as paper raw material and to use starch made from [[flour]] as an additive.\n",
      "\n",
      "The [[Italy|Italians]] used [[hemp]] and [[linen]] rags. In 1276 the first Italian paper mill was built at [[Fabriano]] and, until the 14 century, Italy was a paper supplier in Europe. In 1282 the first [[watermark]] was introduced in [[Bologna]].\n",
      "\n",
      "=== Machine-made paper ===\n",
      "Paper was hard to make. It was cheaper than the old writing materials, but still expensive. A mechanical paper maker was conceived in [[France]] 1798, but invented in [[England]]. At least one [[paper mill]] was using them by 1812.<ref>Hunter, Dard 1978. ''Paper-making: the history and technique of an ancient craft''. Courier Dover</ref><ref>Munsell, Joe 2009 [reprint of 1870 4th ed]. ''A chronology of paper and paper-making''. Albany.</ref> Now the process was cheaper but the [[raw material]] was still expensive.\n",
      "\n",
      "In 1840 Friedrich Gottlob Keller Invented a machine that could make pulp for paper out of [[wood]] fibres (instead of the expensive rag paper). Paper became cheap enough for everyone to buy. Around the same time, other [[invention]]s were made, like the [[pencil]], the [[fountain pen]], and a [[printing press]] that used [[steam power]]. With this new [[information technology]], people wrote more letters, made more books and [[newspaper]]s, and kept more records of what they did.\n",
      "\n",
      "Today, some of the largest paper-producing countries are [[China]], [[USA]], [[Canada]], [[Finland]], [[Sweden]] and [[Russia]]. Paper is produced in large factories called ''paper mills''. They produce hundreds of thousands of tons of paper each year.\n",
      "\n",
      "== Uses of paper ==\n",
      "[[File:Making Paper.gif|thumb|right|200px|Making Chinese paper]]\n",
      "\n",
      "Paper is used for [[write|writing]] and [[wikt:print|printing]]. Books, [[magazine]]s and [[newspaper]]s are printed on paper.\n",
      "\n",
      "Paper is often used for [[money]]. Paper used for money is made in special ways. It does not use wood fiber. It is mostly [[cotton]] with additives to make it hard for people to print their own money. A piece of paper money is called a [[banknote]], a bill or a note.\n",
      "\n",
      "Paper can be used for cleaning. Special forms of paper are used, such as [[paper towel]]s, [[facial tissue]]s or [[toilet paper]].\n",
      "\n",
      "Pretty paper can be used as [[decoration]]. It can be pasted onto the walls of a room; this is called [[wallpaper]]. Paper can be used to wrap gifts. This is called [[wrapping paper]] or [[gift wrap]].\n",
      "\n",
      "Some kinds of paper are strong and can be used in [[box]]es and other [[container|packaging]] [[material]]. Sometimes several layers of paper are held together with [[glue]], to make [[cardboard]].\n",
      "\n",
      "==Related pages==\n",
      "* [[Paper size]]\n",
      "* [[Cardboard]]\n",
      "\n",
      "== References ==\n",
      "{{Reflist}}\n",
      "\n",
      "[[Category:Basic English 850 words]]\n",
      "[[Category:Paper| ]]\n",
      "[[Category:Writing tools]]\n"
     ]
    }
   ],
   "source": [
    "print('ID', row['id'])\n",
    "print('Title', row['title'])\n",
    "print()\n",
    "print('redirect', row['redirect'])\n",
    "print()\n",
    "print('text')\n",
    "print(row['revision']['text']['_VALUE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looking at category now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------\n",
      " title | Category:Computer science \n",
      "-RECORD 1--------------------------\n",
      " title | Category:Sports           \n",
      "-RECORD 2--------------------------\n",
      " title | Category:Athletics        \n",
      "-RECORD 3--------------------------\n",
      " title | Category:Body parts       \n",
      "-RECORD 4--------------------------\n",
      " title | Category:Tools            \n",
      "-RECORD 5--------------------------\n",
      " title | Category:Movies           \n",
      "-RECORD 6--------------------------\n",
      " title | Category:Grammar          \n",
      "-RECORD 7--------------------------\n",
      " title | Category:Mathematics      \n",
      "-RECORD 8--------------------------\n",
      " title | Category:Alphabet         \n",
      "-RECORD 9--------------------------\n",
      " title | Category:Countries        \n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter('title RLIKE \"Category.*\"').select('title')\\\n",
    "    .show(10, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------\n",
      " _title | Catharism   \n",
      " title  | Albigensian \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter('redirect IS NOT NULL')\\\n",
    "    .select('redirect._title', 'title')\\\n",
    "    .show(1, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we get synonymy relationship, our entitles will be titles of articles. Our relationships will be redirects, and link in the related section of the page. Lets get our entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306635\n"
     ]
    }
   ],
   "source": [
    "entities = df.select('title').collect()\n",
    "entities = [r['title'] for r in entities]\n",
    "entities = set(entities)\n",
    "print(len(entities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We may introduce same-category relationship too, we extract the categories too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [e for e in entities if e.startswith('Category:')]\n",
    "entities = [e for e in entities if not e.startswith('Category:')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  now we will get redirects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67878\n"
     ]
    }
   ],
   "source": [
    "redirects = df.filter('redirect IS NOT NULL')\\\n",
    "    .select('redirect._title', 'title').collect()\n",
    "redirects = [(r['_title'], r['title']) for r in redirects]\n",
    "print(len(redirects))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  now we can get articles from revision.text._VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.filter('redirect IS NULL').selectExpr(\n",
    "    'revision.text._VALUE AS text',\n",
    "    'title'\n",
    ").filter('text IS NOT NULL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to get related links, we need to know what section we are in. So we will split the texts into sections. We can then use the RegexMatcher annotator to identify links. Looking at the data, it looks like sections look like == Paper making == as we saw in the example above. Lets define a regex for this, adding in the possibility for extra white space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_ptn = re.compile(r'^ *==[^=]+ *== *$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define a function that will take a partition of the data and generate new rows for the sections. We will need to keep track of the article title section and the text of the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sectionize(rows):\n",
    "    for row in rows:\n",
    "        title = row['title']\n",
    "        text = row['text']\n",
    "        lines = text.split('\\n')\n",
    "        buffer = []\n",
    "        section = 'START'\n",
    "        for line in lines:\n",
    "            if section_ptn.match(line):\n",
    "                yield(title, section, '\\n'.join(buffer))\n",
    "                section = line.strip('=').strip().upper()\n",
    "                buffer = []\n",
    "                continue\n",
    "            buffer.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will call mapPartitions to create a new RDD and convert that to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = data.rdd.mapPartitions(sectionize)\n",
    "sections = spark.createDataFrame(sections, \\\n",
    "                                ['title', 'section', 'text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we take a look at the most common sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(section='START', count=127495),\n",
       " Row(section='REFERENCES', count=35681),\n",
       " Row(section='RELATED PAGES', count=8820),\n",
       " Row(section='HISTORY', count=6683),\n",
       " Row(section='CLUB CAREER STATISTICS', count=3907),\n",
       " Row(section='INTERNATIONAL CAREER STATISTICS', count=2489),\n",
       " Row(section='GEOGRAPHY', count=2476),\n",
       " Row(section='EARLY LIFE', count=2019),\n",
       " Row(section='NOTES', count=1887),\n",
       " Row(section='CAREER', count=1865)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections.select('section').groupBy('section')\\\n",
    "    .count().orderBy(col('count').desc()).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting wiki_regexes.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile wiki_regexes.csv\n",
    "\\[\\[[^\\]]+\\]\\]~link\n",
    "\\{\\{[^\\}]+\\}\\}~anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " config_graph_algo_with_pyspark_variable.py\r\n",
      "'Graph Algo with Pyspark and Neo4j.ipynb'\r\n",
      " Iris-classification-with-pyspark.ipynb\r\n",
      "'Knowledge Bases with Pyspark.ipynb'\r\n",
      " movie_review_analysis.py\r\n",
      "'nlp with pyspark.ipynb'\r\n",
      "'nlp with Spark NLP.ipynb'\r\n",
      "'nlp with tensorflow2 - RNN Irish song generator.ipynb'\r\n",
      "'nlp with tensorflow 2 - text sarcasm sentiment analysis.ipynb'\r\n",
      "'nlp with tensorflow 2 - tokenizer and sequencer.ipynb'\r\n",
      "'Sentiment Analysis using SparkNLP.ipynb'\r\n",
      "'Sequence embedding with pyspark.ipynb'\r\n",
      "'topic modelling with spark nlp.ipynb'\r\n",
      "'What is Graph Analysis .ipynb'\r\n",
      " wiki-entities.csv\r\n",
      " wiki_regexes.csv\r\n",
      " wiki-related.csv\r\n",
      "'Word Embedding Spark-Nlp.ipynb'\r\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = DocumentAssembler()\\\n",
    "    .setInputCol('text')\\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "matcher = RegexMatcher()\\\n",
    "    .setInputCols(['document'])\\\n",
    "    .setOutputCol('matches')\\\n",
    "    .setStrategy(\"MATCH_ALL\")\\\n",
    "    .setExternalRules('wiki_regexes.csv', '~')\n",
    "\n",
    "finisher = Finisher()\\\n",
    "    .setInputCols(['matches'])\\\n",
    "    .setOutputCols(['links'])\n",
    "\n",
    "pipeline = Pipeline()\\\n",
    "    .setStages([assembler, matcher, finisher])\\\n",
    "    .fit(sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted = pipeline.transform(sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### now we will define relationship based on just links occuring anywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4336090\n"
     ]
    }
   ],
   "source": [
    "links = extracted.select('title', 'section', 'links').collect()\n",
    "links = [(r['title'], r['section'], link) for r in links for link in r['links']]\n",
    "links = list(set(links))\n",
    "print(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21317\n"
     ]
    }
   ],
   "source": [
    "related = [(l[0], l[2]) for l in links if l[1] == \"RELATED PAGES\"]\n",
    "related = [(e1, e2.strip('[').strip(']').split('|')[-1]) for e1, e2 in related]\n",
    "related = list(set([(e1, e2) for e1, e2 in related]))\n",
    "print(len(related))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have extracted entities, redirects and related links, now we will create csvs for them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NOTE: now we copy the generated CSVs to neo4j import folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot open directory '../checkpoints/neo4j/data_other_machine/': Permission denied\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../checkpoints/neo4j/data_other_machine/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_df = pd.Series(entities, name='entity').to_frame()\n",
    "entities_df.index.name = 'id'\n",
    "entities_df.to_csv('./wiki-entities.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2id = entities_df.reset_index().set_index('entity')['id'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "redirect_df = []\n",
    "for e1, e2 in redirects:\n",
    "    if e1 in e2id and e2 in e2id:\n",
    "        redirect_df.append((e2id[e1], e2id[e2]))\n",
    "redirect_df = pd.DataFrame(redirect_df, columns=['id1', 'id2'])\n",
    "redirect_df.to_csv('./wiki-redirects.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_df = []\n",
    "for e1, e2 in redirects:\n",
    "    if e1 in e2id and e2 in e2id:\n",
    "        related_df.append((e2id[e1], e2id[e2]))\n",
    "related_df = pd.DataFrame(related_df, columns=['id1', 'id2'])\n",
    "related_df.to_csv('./wiki-related.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### now we will query all entities related to \"Language\", and related to entities that are related to Language(i.e second-order relations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'my_port' from 'config_graph_algo_with_pyspark_variable' (/home/jovyan/projects/spark-nlp/notebooks/config_graph_algo_with_pyspark_variable.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-0ecbacafb089>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mconfig_graph_algo_with_pyspark_variable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmy_ip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_port\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'my_port' from 'config_graph_algo_with_pyspark_variable' (/home/jovyan/projects/spark-nlp/notebooks/config_graph_algo_with_pyspark_variable.py)"
     ]
    }
   ],
   "source": [
    "from config_graph_algo_with_pyspark_variable import my_ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading CSVs into Neo4J database with command \n",
    "LOAD CSV WITH HEADERS FROM \"file:/wiki-entities.csv\" AS csvLine<br>CREATE (e:Entity {id: toInteger(csvLine.id), entity: csvLine.entity})<br><br><br>\n",
    "USING PERIODIC COMMIT :auto <br>LOAD CSV WITH HEADERS FROM \"file:///wiki-redirected.csv\" AS csvLine <br>MATCH (entity1:Entity {id: toInteger(csvLine.id1)}),(entity2:Entity {id: toInteger(csvLine.id2)}) <br>CREATE (entity1)-[:REDIRECTED {conxn: \"redirected\"}]->(entity2)<br><br><br>\n",
    "USING PERIODIC COMMIT :auto <br>LOAD CSV WITH HEADERS FROM \"file:///wiki-related.csv\" AS csvLine <br>MATCH (entity1:Entity {id: toInteger(csvLine.id1)}),(entity2:Entity {id: toInteger(csvLine.id2)}) <br>CREATE (entity1)-[:RELATED {conxn: \"related\"}]->(entity2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will see what we can query. We will get all entities related to \"Language\", and related to entities that are related to Language (i.e. second-order relations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-e448a453bcab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mendpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://{}:7474/db/data/cypher'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_ip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \"\"\"\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    675\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m             )\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;31m# Reset the timeout for the recv() on the socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1250\u001b[0m                 encode_chunked=False):\n\u001b[1;32m   1251\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1296\u001b[0m             \u001b[0;31m# default charset of iso-8859-1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m     def request(self, method, url, body=None, headers={}, *,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\\r\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage_body\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotConnected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m             )\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "MATCH (e:Entity {entity: 'Language'})\n",
    "RETURN e\n",
    "UNION ALL\n",
    "MATCH (\"Entity {entity: 'Language'}\")--(e:Entity)\n",
    "RETURN e\n",
    "UNION ALL\n",
    "MATCH (:Entity {entity: 'Language'})--(e1:Entity)--(e:Entity)\n",
    "RETURN e\n",
    "'''\n",
    "\n",
    "payload = {'query': query, 'params': {}}\n",
    "endpoint = 'http://{}:7474/db/data/cypher'.format(my_ip)\n",
    "\n",
    "response = requests.post(endpoint, json=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
