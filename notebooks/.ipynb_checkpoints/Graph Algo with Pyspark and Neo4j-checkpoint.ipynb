{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neo4j in /opt/conda/lib/python3.7/site-packages (4.0.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from neo4j) (2020.1)\n",
      "Requirement already satisfied: spark-nlp in /opt/conda/lib/python3.7/site-packages (2.5.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install neo4j\n",
    "! pip install spark-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import sparknlp\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import lit, col\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp import DocumentAssembler, Finisher\n",
    "from sparknlp.annotator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = [\n",
    "    'JohnSnowLabs:spark-nlp:2.5.0',\n",
    "    'com.databricks:spark-xml_2.11:0.6.0'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "packages = [\n",
    "    'JohnSnowLabs:spark-nlp:2.2.2',\n",
    "    'com.databricks:spark-xml_2.11:0.6.0'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "    .master('local[*]')\\\n",
    "    .appName('Knowledge Graph')\\\n",
    "    .config('spark.driver.memory', '10g')\\\n",
    "    .config('spark.jars.packages', ','.join(packages))\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simplewiki-20200601-pages-articles-multistream-index.txt.bz2\r\n",
      "simplewiki-20200601-pages-articles-multistream.xml.bz2\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../datasets/wiki_data_for_knowledge_base/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read\\\n",
    "    .format('xml')\\\n",
    "    .option('rootTag', 'mediawiki')\\\n",
    "    .option('rowTag', 'page')\\\n",
    "    .load('../datasets/wiki_data_for_knowledge_base/simplewiki-20200601-pages-articles-multistream.xml.bz2')\\\n",
    "    .persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- ns: long (nullable = true)\n",
      " |-- redirect: struct (nullable = true)\n",
      " |    |-- _VALUE: string (nullable = true)\n",
      " |    |-- _title: string (nullable = true)\n",
      " |-- restrictions: string (nullable = true)\n",
      " |-- revision: struct (nullable = true)\n",
      " |    |-- comment: struct (nullable = true)\n",
      " |    |    |-- _VALUE: string (nullable = true)\n",
      " |    |    |-- _deleted: string (nullable = true)\n",
      " |    |-- contributor: struct (nullable = true)\n",
      " |    |    |-- _VALUE: string (nullable = true)\n",
      " |    |    |-- _deleted: string (nullable = true)\n",
      " |    |    |-- id: long (nullable = true)\n",
      " |    |    |-- ip: string (nullable = true)\n",
      " |    |    |-- username: string (nullable = true)\n",
      " |    |-- format: string (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- minor: string (nullable = true)\n",
      " |    |-- model: string (nullable = true)\n",
      " |    |-- parentid: long (nullable = true)\n",
      " |    |-- sha1: string (nullable = true)\n",
      " |    |-- text: struct (nullable = true)\n",
      " |    |    |-- _VALUE: string (nullable = true)\n",
      " |    |    |-- _bytes: long (nullable = true)\n",
      " |    |    |-- _space: string (nullable = true)\n",
      " |    |-- timestamp: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306635"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looking at page for \"Paper\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df.filter('title = \"Paper\"').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID 3319\n",
      "Title Paper\n",
      "\n",
      "redirect None\n",
      "\n",
      "text\n",
      "[[File:Cranes made by Origami paper.jpg|thumb|132x132px|Paper creations]]\n",
      "[[File:InternationalPaper6413.jpg|right|frame|[[International Paper]] is the world’s largest pulp and paper maker]]\n",
      "[[File:Gutenberg bible Old Testament Epistle of St Jerome.jpg|thumb|right|250px|Before about 1820, most printed books used [[wikt:rag|rag]] paper, usually made from waste cotton rags]]\n",
      "[[File:Manuscripts in the Yunnan Nationalities Museum - DSC03947.JPG|thumb|right|250px|Dai scripture on [[mulberry]]-bark paper, Yunnan, China]]\n",
      "[[File:Papyrus.jpg|thumb|right|250px|Writing on [[papyrus]]]]\n",
      "[[File:Ruins of the guard tower.jpg|thumb|right|220px|Ruins of a watchtower on the [[Great Wall of China]]: see \"first paper\"]]\n",
      "\n",
      "Modern '''paper''' is a thin [[material]] of (mostly) [[wood fibre]]s pressed together. People write on paper with a [[pencil]] or [[pen]], and [[book]]s are made of paper. Paper can absorb [[liquid]]s such as [[water]], so people can clean things with paper.\n",
      "\n",
      "The '''pulp and paper industry''' comprises companies that use wood as raw material and produce [[Pulp (paper)|pulp]], paper, board and other cellulose-based products.\n",
      "\n",
      "== Paper making ==\n",
      "Modern paper is normally made from [[wood]] [[wikt:pulp|pulp]].<ref>{{cite book|page=3|title=The Quantum Universe: everything that can happen does happen|publisher=Allen Lane|date=2011|first1=Brian|first2=Jeff|last1=Cox|last2=Forshaw|isbn=978-1-846-14432-5}}</ref> Wood is ground up and mixed with [[water]] and other [[chemical]]s to make a thin liquid called \"paper pulp\". Paper pulp can be [[Sodium hypochlorite|bleached]] to make paper more white, and [[dye]]s can be added to make colored paper. This pulp is pressed into [[wikt:sheet|sheets]] of paper. Printing is often done on paper before the paper is cut into sheets. Newsprint paper (newspaper) comes in a huge roll, and goes through the printing process as one continuous sheet. It is cut by a machine-driven [[guillotine]] blade later. Folding comes last, then packing for distribution. \n",
      "\n",
      "Sometimes paper is made heavier and more glossy (shiny) by adding [[clay]], and by 'milling' it. Milling is done by [[wikt:squeeze|squeezing]] the paper through a series of rollers. Sometimes paper is made from used or waste paper: this is [[recycling]].\n",
      "\n",
      "Not all paper is made from wood. Other kinds of fiber can be used. People still make paper from [[cotton]], [[linen]] and [[hemp]] for special purposes.\n",
      "\n",
      "== History of paper ==\n",
      "[[Writing]] started long before the invention of paper. People wrote on many kinds of material. They wrote on cloth, on the stone walls and on wood. In [[Mesopotamia]] the [[Sumer]]ians wrote on [[clay]] tablets, many of which have survived today. In Europe, people wrote on [[vellum]].\n",
      "\n",
      "=== First paper ===\n",
      "Many [[century|centuries]] ago&nbsp;–&nbsp;as early as the [[3rd millennium BC]] (that's over 2000 BC)&nbsp;–&nbsp;people in [[Egypt]] made a kind of paper from the [[papyrus]] plant.<ref name = Skeat>[http://www-user.uni-bremen.de/~wie/Egerton/BellSkeat2.html H. Idris Bell and T.C. Skeat, 1935. \"Papyrus and its uses\"] ([[British Museum]] pamphlet).</ref> This is where the word 'paper' comes from. The people of [[Greece]] and [[Rome]] learned to do this too. The Romans wrote on [[parchment]] (made from animal skin), on [[wax]]ed tablets and on wood (see [[Vindolanda]]).\n",
      "\n",
      "In [[China]] 105 AD, the [[eunuch]] [[Cai Lun]] told his Emperor he had made paper. They had previously used [[bamboo]] and [[silk]].<ref>Han dynasty 206BC–220 AD.</ref><ref name=Carter>Carter, Thomas Francis 1925. ''The invention of printing in China and its spread westward''. Columbia N.Y.</ref> The material used in this ancient paper included [[cotton]] [[wikt:rag|rags]], [[hemp]], various plant fibres and old [[Fishing net|fish nets]]. The oldest existing paper with writing on it was found in the ruins of a watchtower in the [[Great Wall of China]]. It dates to about 150 AD.<ref name=Carter/><sup>p5</sup><ref>Stein, M. Aurel 1921. ''Serindia''. London 1921.</ref><ref>Papermaking. 2007. In: ''Encyclopedia Britannica'', from ''Encyclopedia Britannica Online''.</ref> Even earlier paper (but with no writing on it) has been claimed: \"The oldest surviving piece of paper in the world is made of hemp fibers, discovered in 1957 in a tomb near Xian, China, and dates from between the years 140 and 87 BC\".<ref>Temple, Robert 1986. ''The genius of China: 3,000 Years of science, discovery, and invention''. Simon and Schuster, New York.</ref> Paper-making was regarded by the Chinese as so valuable that they kept it secret as long as they could.\n",
      "\n",
      "=== Spread of paper ===\n",
      "People in [[Japan]] learned how to make paper with fibres of the [[mulberry]] tree, around 610 AD. This is called Japanese paper or ''[[Washi]]''. The Chinese invention spread to [[India]], and then to the [[Middle East]], and then to [[Italy]].\n",
      "\n",
      "An opportunity occurred after The Battle of Talas in 751. Then an [[Arab]] army captured soldiers of the Chinese. There were some paper makers among the captured soldiers. From them, paper-making spread throughout the [[Islamic world]].  In 757, a paper mill was built at [[Samarkand]]. People learned to use [[linen]] as paper raw material and to use starch made from [[flour]] as an additive.\n",
      "\n",
      "The [[Italy|Italians]] used [[hemp]] and [[linen]] rags. In 1276 the first Italian paper mill was built at [[Fabriano]] and, until the 14 century, Italy was a paper supplier in Europe. In 1282 the first [[watermark]] was introduced in [[Bologna]].\n",
      "\n",
      "=== Machine-made paper ===\n",
      "Paper was hard to make. It was cheaper than the old writing materials, but still expensive. A mechanical paper maker was conceived in [[France]] 1798, but invented in [[England]]. At least one [[paper mill]] was using them by 1812.<ref>Hunter, Dard 1978. ''Paper-making: the history and technique of an ancient craft''. Courier Dover</ref><ref>Munsell, Joe 2009 [reprint of 1870 4th ed]. ''A chronology of paper and paper-making''. Albany.</ref> Now the process was cheaper but the [[raw material]] was still expensive.\n",
      "\n",
      "In 1840 Friedrich Gottlob Keller Invented a machine that could make pulp for paper out of [[wood]] fibres (instead of the expensive rag paper). Paper became cheap enough for everyone to buy. Around the same time, other [[invention]]s were made, like the [[pencil]], the [[fountain pen]], and a [[printing press]] that used [[steam power]]. With this new [[information technology]], people wrote more letters, made more books and [[newspaper]]s, and kept more records of what they did.\n",
      "\n",
      "Today, some of the largest paper-producing countries are [[China]], [[USA]], [[Canada]], [[Finland]], [[Sweden]] and [[Russia]]. Paper is produced in large factories called ''paper mills''. They produce hundreds of thousands of tons of paper each year.\n",
      "\n",
      "== Uses of paper ==\n",
      "[[File:Making Paper.gif|thumb|right|200px|Making Chinese paper]]\n",
      "\n",
      "Paper is used for [[write|writing]] and [[wikt:print|printing]]. Books, [[magazine]]s and [[newspaper]]s are printed on paper.\n",
      "\n",
      "Paper is often used for [[money]]. Paper used for money is made in special ways. It does not use wood fiber. It is mostly [[cotton]] with additives to make it hard for people to print their own money. A piece of paper money is called a [[banknote]], a bill or a note.\n",
      "\n",
      "Paper can be used for cleaning. Special forms of paper are used, such as [[paper towel]]s, [[facial tissue]]s or [[toilet paper]].\n",
      "\n",
      "Pretty paper can be used as [[decoration]]. It can be pasted onto the walls of a room; this is called [[wallpaper]]. Paper can be used to wrap gifts. This is called [[wrapping paper]] or [[gift wrap]].\n",
      "\n",
      "Some kinds of paper are strong and can be used in [[box]]es and other [[container|packaging]] [[material]]. Sometimes several layers of paper are held together with [[glue]], to make [[cardboard]].\n",
      "\n",
      "==Related pages==\n",
      "* [[Paper size]]\n",
      "* [[Cardboard]]\n",
      "\n",
      "== References ==\n",
      "{{Reflist}}\n",
      "\n",
      "[[Category:Basic English 850 words]]\n",
      "[[Category:Paper| ]]\n",
      "[[Category:Writing tools]]\n"
     ]
    }
   ],
   "source": [
    "print('ID', row['id'])\n",
    "print('Title', row['title'])\n",
    "print()\n",
    "print('redirect', row['redirect'])\n",
    "print()\n",
    "print('text')\n",
    "print(row['revision']['text']['_VALUE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looking at category now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------\n",
      " title | Category:Computer science \n",
      "-RECORD 1--------------------------\n",
      " title | Category:Sports           \n",
      "-RECORD 2--------------------------\n",
      " title | Category:Athletics        \n",
      "-RECORD 3--------------------------\n",
      " title | Category:Body parts       \n",
      "-RECORD 4--------------------------\n",
      " title | Category:Tools            \n",
      "-RECORD 5--------------------------\n",
      " title | Category:Movies           \n",
      "-RECORD 6--------------------------\n",
      " title | Category:Grammar          \n",
      "-RECORD 7--------------------------\n",
      " title | Category:Mathematics      \n",
      "-RECORD 8--------------------------\n",
      " title | Category:Alphabet         \n",
      "-RECORD 9--------------------------\n",
      " title | Category:Countries        \n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter('title RLIKE \"Category.*\"').select('title')\\\n",
    "    .show(10, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------\n",
      " _title | Catharism   \n",
      " title  | Albigensian \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter('redirect IS NOT NULL')\\\n",
    "    .select('redirect._title', 'title')\\\n",
    "    .show(1, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we get synonymy relationship, our entitles will be titles of articles. Our relationships will be redirects, and link in the related section of the page. Lets get our entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306635\n"
     ]
    }
   ],
   "source": [
    "entities = df.select('title').collect()\n",
    "entities = [r['title'] for r in entities]\n",
    "entities = set(entities)\n",
    "print(len(entities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We may introduce same-category relationship too, we extract the categories too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [e for e in entities if e.startswith('Category:')]\n",
    "entities = [e for e in entities if not e.startswith('Category:')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  now we will get redirects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67878\n"
     ]
    }
   ],
   "source": [
    "redirects = df.filter('redirect IS NOT NULL')\\\n",
    "    .select('redirect._title', 'title').collect()\n",
    "redirects = [(r['_title'], r['title']) for r in redirects]\n",
    "print(len(redirects))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  now we can get articles from revision.text._VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.filter('redirect IS NULL').selectExpr(\n",
    "    'revision.text._VALUE AS text',\n",
    "    'title'\n",
    ").filter('text IS NOT NULL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to get related links, we need to know what section we are in. So we will split the texts into sections. We can then use the RegexMatcher annotator to identify links. Looking at the data, it looks like sections look like == Paper making == as we saw in the example above. Lets define a regex for this, adding in the possibility for extra white space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_ptn = re.compile(r'^ *==[^=]+ *== *$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define a function that will take a partition of the data and generate new rows for the sections. We will need to keep track of the article title section and the text of the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sectionize(rows):\n",
    "    for row in rows:\n",
    "        title = row['title']\n",
    "        text = row['text']\n",
    "        lines = text.split('\\n')\n",
    "        buffer = []\n",
    "        section = 'START'\n",
    "        for line in lines:\n",
    "            if section_ptn.match(line):\n",
    "                yield(title, section, '\\n'.join(buffer))\n",
    "                section = line.strip('=').strip().upper()\n",
    "                buffer = []\n",
    "                continue\n",
    "            buffer.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will call mapPartitions to create a new RDD and convert that to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = data.rdd.mapPartitions(sectionize)\n",
    "sections = spark.createDataFrame(sections, \\\n",
    "                                ['title', 'section', 'text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we take a look at the most common sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(section='START', count=127495),\n",
       " Row(section='REFERENCES', count=35681),\n",
       " Row(section='RELATED PAGES', count=8820),\n",
       " Row(section='HISTORY', count=6683),\n",
       " Row(section='CLUB CAREER STATISTICS', count=3907),\n",
       " Row(section='INTERNATIONAL CAREER STATISTICS', count=2489),\n",
       " Row(section='GEOGRAPHY', count=2476),\n",
       " Row(section='EARLY LIFE', count=2019),\n",
       " Row(section='NOTES', count=1887),\n",
       " Row(section='CAREER', count=1865)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections.select('section').groupBy('section')\\\n",
    "    .count().orderBy(col('count').desc()).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting wiki_regexes.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile wiki_regexes.csv\n",
    "\\[\\[[^\\]]+\\]\\]~link\n",
    "\\{\\{[^\\}]+\\}\\}~anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Graph Algo with Pyspark and Neo4j.ipynb'\r\n",
      " Iris-classification-with-pyspark.ipynb\r\n",
      "'Knowledge Bases with Pyspark.ipynb'\r\n",
      " movie_review_analysis.py\r\n",
      "'nlp with pyspark.ipynb'\r\n",
      "'nlp with Spark NLP.ipynb'\r\n",
      "'nlp with tensorflow2 - RNN Irish song generator.ipynb'\r\n",
      "'nlp with tensorflow 2 - text sarcasm sentiment analysis.ipynb'\r\n",
      "'nlp with tensorflow 2 - tokenizer and sequencer.ipynb'\r\n",
      "'Sentiment Analysis using SparkNLP.ipynb'\r\n",
      "'Sequence embedding with pyspark.ipynb'\r\n",
      "'topic modelling with spark nlp.ipynb'\r\n",
      "'What is Graph Analysis .ipynb'\r\n",
      " wiki_regexes.csv\r\n",
      "'Word Embedding Spark-Nlp.ipynb'\r\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = DocumentAssembler()\\\n",
    "    .setInputCol('text')\\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "matcher = RegexMatcher()\\\n",
    "    .setInputCols(['document'])\\\n",
    "    .setOutputCol('matches')\\\n",
    "    .setStrategy(\"MATCH_ALL\")\\\n",
    "    .setExternalRules('wiki_regexes.csv', '~')\n",
    "\n",
    "finisher = Finisher()\\\n",
    "    .setInputCols(['matches'])\\\n",
    "    .setOutputCols(['links'])\n",
    "\n",
    "pipeline = Pipeline()\\\n",
    "    .setStages([assembler, matcher, finisher])\\\n",
    "    .fit(sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted = pipeline.transform(sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### now we will define relationship based on just links occuring anywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4336090\n"
     ]
    }
   ],
   "source": [
    "links = extracted.select('title', 'section', 'links').collect()\n",
    "links = [(r['title'], r['section'], link) for r in links for link in r['links']]\n",
    "links = list(set(links))\n",
    "print(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
